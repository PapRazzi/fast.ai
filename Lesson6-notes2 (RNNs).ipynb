{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNNs)\n",
    "\n",
    "## Intuitition\n",
    "Ordinary neural networks have some limitations: they take a fixed size input and give a fixed sized output. For example, they take in a number of pixels, and give out a list of predictions for character likelihood in a vector.\n",
    "\n",
    "Another problem is that they have know concept of memory or context. For example, if you were using them to predict words in a sentence, they would just take in all of the words of a sentence at once, and predict the next word, not taking into account which words might have come previously in their calculations, just predicting that the next word should be a proper noun, or whatever.\n",
    "\n",
    "RNNs solve this problem. RNNs process sequences. Normal neural networks can be thought of as calculating an output based on some input. RNNs can be thought of as calculating an output based on the input BUT ALSO on the history of other inputs as well.\n",
    "\n",
    "Imagine a loop.\n",
    "\n",
    "The first time you go through the loop, you feed in some input and get some output.\n",
    "\n",
    "The next time you go through the look, you feed in some input AND you feed in the previous output as input too.\n",
    "\n",
    "Thus you can get predictions for sequences of data based on previous sequences and new input.\n",
    "\n",
    "For this reason, RNNs have many applications such as stock prediction, video frame captioning (take into account previous frames), segment-to-segment machine translation (translate by grammatical segements instead of processing word-by-word), etc.\n",
    "\n",
    "## Note on LTSMs\n",
    "In practice, the RNNs are implemented as LTSM (Long Short Term Memory). This means that when generating predictions, they can choose use some sub-networks to choose to ignore some data, hold some data, and select some data for the prediction.\n",
    "\n",
    "Since RNNs just take in a vector and spit out a vector, you can easily feed one RNN into another.\n",
    "\n",
    "## Note on tanh\n",
    "RNNs use hyperbolic tan as a squashing function to stop gradient explosions. I.e, it keeps the values between -1 to 1 to stop the gradients blowing up to huge/tiny numbers, which might happen if they were doubled/halfed each iteration.\n",
    "\n",
    "It's very similar to the sigmoid function.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/tanh.jpg\" width=500 height=350>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LTSM Example\n",
    "Ref: https://www.youtube.com/watch?v=WCUNPb-5EYI\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/lstm0.jpg\" width=600 height=450>\n",
    "\n",
    "First, we take our previous input, our new input, and our list of predictions. We get a list of predictions: Doug, or saw. Doug and saw are put into memory. Our trained weights predict the next most likely word is saw. This gives us a new list of predictions: Doug, Spot, and Jane.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/lstm1.jpg\" width=600 height=450>\n",
    "\n",
    "We then repeat the process with our new predictions. When we get to the \"ignore\" layer, based on our previous memory, we know we've already seen Doug, so we ignore it, leaving us to choose either Jane or Spot.\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/ltsm2.jpg\" width=600 height=450>\n",
    "\n",
    "In this way, RNNs can take account of what they previously saw when making new predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## A very simple RNN\n",
    "Ref: https://www.youtube.com/watch?v=UNmqTiOnRfg\n",
    "\n",
    "Imagine we have three food types represented by one-hot encoded vectors. Each good gets cooked in a sequence, depending on the weather.\n",
    "\n",
    "So in this example, food is our previous output, and weather is our new input. We need to remember the last food cooked, and combine it with the weather.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/rnn0.jpg\" width=600 height=450>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/rnn1.jpg\" width=600 height=450>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/rnn2.jpg\" width=600 height=450>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/rnn3.jpg\" width=600 height=450>\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/rnn4.jpg\" width=600 height=450>\n",
    "\n",
    "So when implementing our RNNs, we multiply the previous output (as input) by a weight matrix, and also our new input by a weight matrix too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Implementation\n",
    "In this example, we will download the collected works of Nietzche, and then get it to predict the next character given n starting characters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "from fastai.io import *\n",
    "from fastai.conv_learner import *\n",
    "\n",
    "from fastai.column_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH='data/nietzsche/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "text = open(f'{PATH}nietzsche.txt').read()\n",
    "print('corpus length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrible\\nseriousness and clumsy importunity with which they have usually paid\\ntheir addresses to Truth, have been unskilled and unseemly methods for\\nwinning a woman? Certainly she has never allowed herself '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take a look at the first 400 words\n",
    "text[:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of predicting word by word, we will predict char by char. This has a few advantages: you don't have to worry about unrecognized/rare words, and there are going to be fewer unique items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars 85\n"
     ]
    }
   ],
   "source": [
    "# Insert into set to get rid of dupes\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars', vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert a value for padding\n",
    "chars.insert(0, '\\0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxyzÆäæéë'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create mappings from characters to indices, and indices to characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use a list of indices generated using our mappings above when dealing with the text from now on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = [char_indices[c] for c in text]\n",
    "indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in indices[:70])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A 3 char model\n",
    "Now let's build a model where we can pass in 3 chars and get the fourth back. For this to work, we will need to grab the 0, 1, 2, 3 position chars in a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get every nth element in indices -- our string of letters converted to indices\n",
    "# range statement = get 0...len-3, skipping 3 chars at a time\n",
    "char_skip = 3\n",
    "\n",
    "c1_data = [indices[i] for i in range(0, len(indices)-char_skip, char_skip)]\n",
    "c2_data = [indices[i+1] for i in range(0, len(indices)-char_skip, char_skip)]\n",
    "c3_data = [indices[i+2] for i in range(0, len(indices)-char_skip, char_skip)]\n",
    "c4_data = [indices[i+3] for i in range(0, len(indices)-char_skip, char_skip)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up input (put into array)\n",
    "x1 = np.stack(c1_data)\n",
    "x2 = np.stack(c2_data)\n",
    "x3 = np.stack(c3_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the output\n",
    "y = np.stack(c4_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create model\n",
    "(See diagrams for reference: https://github.com/fastai/fastai/blob/master/courses/dl1/ppt/lesson6.pptx)\n",
    "\n",
    "Our first version of the model will look like this:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/rnn5.jpg\" width=650 height=450>\n",
    "\n",
    "Note the same coloured arrows mean we are using the same weight matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_hidden_activations = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I.e., size of embedding matrix\n",
    "num_of_factors = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, num_of_factors):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, num_of_factors)\n",
    "        \n",
    "        # Set up the first hidden layer -- from input to hidden layer (green arrow)\n",
    "        self.input_layer = nn.Linear(num_of_factors, num_of_hidden_activations)\n",
    "        \n",
    "        # Set up the hidden layer -- from hidden to hidden (orange arrow)\n",
    "        self.hidden_layer = nn.Linear(num_of_hidden_activations, num_of_hidden_activations)\n",
    "        \n",
    "        # Set up the output layer -- from hidden to output (blue arrow)\n",
    "        self.output_layer = nn.Linear(num_of_hidden_activations, vocab_size)\n",
    "        \n",
    "    # Take in 3 chars\n",
    "    def forward(self, c1, c2, c3):\n",
    "        \n",
    "        # Feed inputs through the embedding layer, then the hidden layer, then ReLU\n",
    "        input_char1 = F.relu(self.input_layer(self.embedding(c1)))\n",
    "        input_char2 = F.relu(self.input_layer(self.embedding(c2)))\n",
    "        input_char3 = F.relu(self.input_layer(self.embedding(c3)))\n",
    "        \n",
    "        # Set up hidden activations\n",
    "        hidden_activations = V(torch.zeros(input_char1.size()).cuda())\n",
    "        \n",
    "        # Put the input through the hidden layers, adding them together\n",
    "        # We use tanh to keep things between -1 and 1\n",
    "        hidden_activations = F.tanh(self.hidden_layer(hidden_activations+input_char1))\n",
    "        hidden_activations = F.tanh(self.hidden_layer(hidden_activations+input_char2))\n",
    "        hidden_activations = F.tanh(self.hidden_layer(hidden_activations+input_char3))\n",
    "        \n",
    "        # Finally use softmax to get most likely char\n",
    "        return F.log_softmax(self.output_layer(hidden_activations))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our model data (just to avoid using PyTorch loaders)\n",
    "model_data = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Char3Model(vocab_size, num_of_factors).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up an iterator so we can grab mini-batches and iterate through them\n",
    "iterator = iter(model_data.trn_dl)\n",
    "\n",
    "# Grab the Xs and Ys for a mini-batch (as tensors?)\n",
    "*xs,yt = next(iterator)\n",
    "\n",
    "# Convert tensor to variable and pass to the model, giving a tensor of floats\n",
    "t = model(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-4.3439 -4.4141 -4.4359  ...  -4.4682 -4.5836 -4.4587\n",
       "-4.5228 -4.3487 -4.5125  ...  -4.6175 -4.4831 -4.5724\n",
       "-4.0663 -4.3157 -4.6830  ...  -4.6195 -4.3445 -4.3563\n",
       "          ...             ⋱             ...          \n",
       "-4.1089 -4.2008 -4.4603  ...  -4.3261 -4.5919 -4.4617\n",
       "-4.1337 -4.3263 -4.5595  ...  -4.2842 -4.5107 -4.5387\n",
       "-4.1154 -4.3211 -4.4799  ...  -4.1908 -4.6491 -4.5378\n",
       "[torch.cuda.FloatTensor of size 512x85 (GPU 0)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Size is 512 (batch size) * probability of each of the vocab items (85)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up our optimizer\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f35933c7884f2ca7b1713818d71834",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.101551   1.388842  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.3888421]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set learning rate annealing and run again\n",
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975f744b4f5e44c688daf1a37c050d07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.863796   0.42308   \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.42307997]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    # Convert character in the input to tensor\n",
    "    indices = T(np.array([char_indices[c] for c in inp]))\n",
    "    \n",
    "    probabilities = model(*VV(indices))\n",
    "    \n",
    "    i = np.argmax(to_np(probabilities))\n",
    "    \n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('y. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next(' an')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to RNN\n",
    "We will now convert the code to be an RNN. The code is largely the same, except now we loop our hidden layers. The output is also taken into the loop. In other words, the output will become the new input.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/rnn6.jpg\" width=600 height=450>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_skip=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Through 0-7, create a list of every 8th character with that starting point. These will be the inputs.\n",
    "input_character_data = [[indices[i+j] for i in range(char_skip)] for j in range(len(indices)-char_skip)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then create a list of the next char in the series. These will be the training labels.\n",
    "output_character_data = [indices[j+char_skip] for j in range(len(indices)-char_skip)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.stack(input_character_data, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600885, 8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.stack(output_character_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
       "       [42, 29, 30, 25, 27, 29,  1,  1],\n",
       "       [29, 30, 25, 27, 29,  1,  1,  1],\n",
       "       [30, 25, 27, 29,  1,  1,  1, 43],\n",
       "       [25, 27, 29,  1,  1,  1, 43, 45],\n",
       "       [27, 29,  1,  1,  1, 43, 45, 40],\n",
       "       [29,  1,  1,  1, 43, 45, 40, 40],\n",
       "       [ 1,  1,  1, 43, 45, 40, 40, 39]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:char_skip, :char_skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 43, 45, 40, 40, 39, 43])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:char_skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_indices = get_cv_idxs(len(indices)-char_skip-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = ColumnarModelData.from_arrays('.', validation_indices, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is essentially the same as our earlier model\n",
    "\n",
    "class CharLoopModel(nn.Module):\n",
    "    # This is an RNN!\n",
    "    def __init__(self, vocab_size, num_of_factors):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, num_of_factors)\n",
    "        self.input_layer = nn.Linear(num_of_factors, num_of_hidden_activations)\n",
    "        self.hidden_layer = nn.Linear(num_of_hidden_activations, num_of_hidden_activations)\n",
    "        self.output_layer = nn.Linear(num_of_hidden_activations, vocab_size)\n",
    "        \n",
    "    def forward(self, *chars):\n",
    "        bs = chars[0].size(0)\n",
    "        h = V(torch.zeros(bs, num_of_hidden_activations).cuda())\n",
    "        for char in chars:\n",
    "            # Loop around our input layer and hidden layers\n",
    "            inp = F.relu(self.input_layer(self.embedding_layer(char)))\n",
    "            h = F.tanh(self.hidden_layer(h+inp))\n",
    "        \n",
    "        return F.log_softmax(self.output_layer(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLoopModel(vocab_size, num_of_factors).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73fdd658216f4537944afc004f8cac46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.98031    1.956332  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.956332]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7779a54048a4563883e8a2278b80907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.696746   1.697028  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.6970276]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One issue with the model above is that we are adding the input and the hidden activations (h) so far. The input state represents the encoding of the characters, but h is the encoding of the series of characters so far. Since these are different types of info, we want to concatenate them, not add them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    # This is an RNN!\n",
    "    def __init__(self, vocab_size, num_of_factors):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, num_of_factors)\n",
    "        self.input_layer = nn.Linear(num_of_factors+num_of_hidden_activations, num_of_hidden_activations)\n",
    "        self.hidden_layer = nn.Linear(num_of_hidden_activations, num_of_hidden_activations)\n",
    "        self.output_layer = nn.Linear(num_of_hidden_activations, vocab_size)\n",
    "        \n",
    "    def forward(self, *chars):\n",
    "        bs = chars[0].size(0)\n",
    "        h = V(torch.zeros(bs, num_of_hidden_activations).cuda())\n",
    "        for char in chars:\n",
    "            # Loop around our input layer and hidden layers\n",
    "            inp = torch.cat((h, self.embedding_layer(char)), 1)\n",
    "            inp = F.relu(self.input_layer(inp))\n",
    "            h = F.tanh(self.hidden_layer(inp))\n",
    "        \n",
    "        return F.log_softmax(self.output_layer(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharLoopConcatModel(vocab_size, num_of_factors).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(model_data.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = model(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ead3dfa6520466988a329d08a14da53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.843979   1.822812  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.8228117]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98142833cd1c460e9744b50f873be117",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.737225   1.738723  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7387227]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))\n",
    "    p = m(*VV(idxs))\n",
    "    i = np.argmax(to_np(p))\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'t'"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('part of ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Implementation\n",
    "The PyTorch implementation is largely the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, num_of_factors):\n",
    "        super().__init__()\n",
    "        self.embedding_layer = nn.Embedding(vocab_size, num_of_factors)\n",
    "        self.rnn = nn.RNN(num_of_factors, num_of_hidden_activations)\n",
    "        self.output_layer = nn.Linear(num_of_hidden_activations, vocab_size)\n",
    "        \n",
    "    def forward(self, *chars):\n",
    "        batch_size = chars[0].size(0)\n",
    "        hidden_activations = V(torch.zeros(1, batch_size, num_of_hidden_activations))\n",
    "        inp = self.embedding_layer(torch.stack(chars))\n",
    "        \n",
    "        # Basically the difference is it just runs the loop for us\n",
    "        outp,hidden_activations = self.rnn(inp, hidden_activations)\n",
    "        \n",
    "        # In PyTorch they pass back all of the hidden layer outputs\n",
    "        # We just want the last one, so we get it with [-1]\n",
    "        return F.log_softmax(self.output_layer(outp[-1]), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRnn(vocab_size, num_of_factors).cuda()\n",
    "opt = optim.Adam(model.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(model_data.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 42])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = model.embedding_layer(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,num_of_hidden_activations))\n",
    "outp, hn = model.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 85])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = model(*V(xs))\n",
    "\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323239bfcce74f18a82eb0f22e51e345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=4), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.880866   1.852416  \n",
      "    1      1.686484   1.678685                              \n",
      "    2      1.597526   1.598038                              \n",
      "    3      1.527368   1.550226                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5502259]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5c7db512a54c34945b2144398b037f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.477367   1.51327   \n",
      "    1      1.480211   1.508043                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.5080433]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(model, model_data, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for those in the same to the same to the same to'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
