{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent/Optimization Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jacobian\n",
    "The Jacobian matrix stores all of the first order partial derivatives of a vector valued function.\n",
    "(Reminder: vector valued function = a function with multiple output values [into a vector]).\n",
    "\n",
    "E.g.,\n",
    "\n",
    "$f(x,y) = \\begin{equation}\n",
    "\\left[\n",
    "  \\begin{array}{cccc}\n",
    "  x^2y\\\\\n",
    "  5x + sin y\n",
    "  \\end{array}\n",
    "\\right]\n",
    "\\end{equation}$\n",
    "\n",
    "Then we can break it down into:\n",
    "\n",
    "$f_1(x,y) = x^2y$\n",
    "\n",
    "and\n",
    "\n",
    "$f_2(x,y) = 5x + sin y$\n",
    "\n",
    "Then the Jacobian matrix becomes:\n",
    "\n",
    "$J_f(x,y) = \\begin{equation}\n",
    "\\left[\n",
    "  \\begin{array}{cccc}\n",
    "  \\frac{\\delta{f_1}}{\\delta{x}} \\frac{\\delta{f_1}}{\\delta{y}}\\\\\n",
    "  \\frac{\\delta{f_2}}{\\delta{x}} \\frac{\\delta{f_2}}{\\delta{y}}\n",
    "  \\end{array}\n",
    "\\right]\n",
    "\\end{equation}$\n",
    "\n",
    "$J_f(x,y) = \\begin{equation}\n",
    "\\left[\n",
    "  \\begin{array}{cccc}\n",
    "  2xy  &x^2\\\\\n",
    "  5 &cos y\n",
    "  \\end{array}\n",
    "\\right]\n",
    "\\end{equation}$\n",
    "\n",
    "The __Hessian__ matrix is similar, but it stores the second order partial derivatives (the derivative of the derivative)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent\n",
    "\n",
    "The gradient descent training process is as follows:\n",
    "\n",
    "1. Randomly choose some weights for your network\n",
    "2. Perform a forward pass on your data to get predictions for your data\n",
    "3. Use a loss function to calculate how well your network is performing. The loss function will calculate some measure of difference between your predictions and the correct values. The lower the loss function, the better.\n",
    "4. Calculate the gradient: this is the derivative of the cost function. Recall that a gradient will give you the slope of steepest ascent.\n",
    "5. Update your weights by doing `weights - (gradient*learning rate)`. This will minimize the loss function, since we're moving \"downhill\", and so improve our weights. (Make the weights closer to values that will give more accurate predictions.)\n",
    "6. Repeat steps 2-5\n",
    "7. Once we have processed all of our data, repeat 2-6 for another epoch, and so on until we have good weights\n",
    "\n",
    "#### \"Stochastic\"\n",
    "\n",
    "What makes gradient descent __stochastic__ is that we evaluate our loss (aka error or cost) using just a subset of a data -- a mini-batch. This is because each update is a _stochastic approximation_ of the \"true\" cost gradient, and as as result the path down the function may \"zig zag\" a bit, but it should still converge at a minima as long as the function is convex.\n",
    "\n",
    "#### Backpropagation\n",
    "\n",
    "Since our cost function involves calculating a prediction by using the various activation functions in our network (weighted sums, ReLU, Sigmoid, etc.), taking the derivative of this function will necessarily involve taking the derivative of our entire network. In practical terms, this is implemented by treating of each activation as a \"gate\" in a \"circuit\". When we're doing our forward pass, we also calculate the derivative of each \"gate\" and then use this derivative during the backward pass. During the backward pass, we just keep applying the chain rule to work out what effect this gate (mathematical operation) has on the final output.\n",
    "\n",
    "This lecture has a good walkthrough of the process: https://www.youtube.com/watch?v=i94OvYb6noo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Gradient Descent in Excel\n",
    "`(See graddesx.xlsm)`\n",
    "\n",
    "Imagine we have the simple function $y = ax + b$ ($a = slope, b = constant$).\n",
    "We initialize them so $a=2$ and $b=30$ and generate some data. \n",
    "\n",
    "In \"real\" machine learning, we can think of $x$ and $y$ as our training data. For example, $x$ might be a picture of a cat or dog, and $y$ could be a label saying cat or dog. We want to calculate the correct value for $a$ and $b$ such that it predicts the label correctly.\n",
    "\n",
    "Now, to do our learning, let's pretend we don't know the values for $a$ and $b$. Just initialize them to 1.\n",
    "\n",
    "1. Get a prediction for y using our formula $y = ax + b$ (in a neural network, this formula could be the throughput of all the layers -- the weighted sum of a linear linear > ReLU > Softmax, etc.)\n",
    "2. Calculate the error for our function by comparing the actual value and predicted value. For example, $(actual_y_value - predicted_y_value) ^2$\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/gd1.jpg\" width=650 height=500>\n",
    "\n",
    "Now, how do we improve our weights? Notice that the cost function (step 2 above) will be closer to 0 when the prediction is closer to the actual value. So we want to minimize this cost function. To minimize a function, we can:\n",
    "\n",
    "1. Calculate the gradient of the function (the slope of steepest ascent)\n",
    "2. Step \"down\" the gradient by some learning rate\n",
    "\n",
    "(I think there might be a slightly mistake in the Excel file here, as it assumes the cost function is predicted - actual, which flips a sign on the derivative, but it still works)\n",
    "\n",
    "So, we can write our cost (error) function as:\n",
    "\n",
    "$((ax+b)-y)^2$\n",
    "\n",
    "($ax+b$ is our prediction, $y$ is our actual value).\n",
    "\n",
    "If we calculate the partial derivatives for this...\n",
    "\n",
    "The change in our function with respect to $b$ gives us:\n",
    "\n",
    "$\\frac{\\delta{e}}{\\delta{b}} = 2(ax+b-y)$\n",
    "\n",
    "And with $a$:\n",
    "\n",
    "$\\frac{\\delta{e}}{\\delta{a}} = 2x(ax+b-y)$\n",
    "\n",
    "So, to update our weights, we calulate the gradients using this formula, and then do:\n",
    "\n",
    "$new\\_weight = old\\_weight-(gradient*learning\\_rate)$\n",
    "\n",
    "This gives us some weights that should decrease our cost function on the next iteration (at least they would for the sample we just ran), and so we repeat the cycle with them.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/gd2.jpg\" width=600 height=450>\n",
    "\n",
    "Once we have ran through all of our data, we have completed one epoch of training, and we can calculate the RMSE for our entire data set, and start another epoch.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/gd3.jpg\" width=600 height=450>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent as Circuit/Chain Rule\n",
    "\n",
    "Ref: https://www.youtube.com/watch?v=i94OvYb6noo\n",
    "\n",
    "It's been suggested that backpropagation is just \"keep applying the chain rule\". This video has a good explanation and examples.\n",
    "\n",
    "During the forward pass, we also store the derivative of each of our function \"gates\", then, during the backprop, we multiply the previous gradient by the gradient for this gate, and so on. This lets us run backprop with around the same efficiency as the forward pass. It would be far too complex to try and compute a huge derivative for the entire function, so we do it bit by bit instead. In fact, if you look at PyTorch, a lot of it consists of these \"gate\" modules.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/gd04.jpg\" width=650 height=500>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
