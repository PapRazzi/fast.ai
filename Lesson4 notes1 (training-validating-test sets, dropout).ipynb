{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training/Validation/Test\n",
    "When creating our model, note that we have 3 sets:\n",
    "\n",
    "* The training set\n",
    "* The validation set\n",
    "* The test set\n",
    "\n",
    "The training set is used with stochastic gradient descent to train the various weights within the network.\n",
    "\n",
    "The test set is used to check how good our model is -- can it correctly identify data it hasn't seen before?\n",
    "\n",
    "But what about the validation set?\n",
    "\n",
    "Fast.ai tells us the validation set is used to determine what kind of model to use, but let's dig deeper.\n",
    "\n",
    "We must go back to the concept of _underfitting_ and _overfitting_.\n",
    "\n",
    "Thinking of it like linear regression, if a model is _underfitting_, it would be like there was a straight line going through the data points, but the line is a bit to general to accurately predict future data points.\n",
    "\n",
    "If a model is _overfitting_, it is like the line hits all of the data points exactly. This might seem fine, but the line would be so random that it wouldn't be able to predict any new, unseen data.\n",
    "\n",
    "(Reminder: You can check if your model is overfitting because the training loss will be a lot lower than the validation loss.)\n",
    "\n",
    "What you want is a line that is _just right_. That is, it goes through the data points pretty closely, but there is still a pattern to the line, so you can use it to predict future data.\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/pekoto/fast.ai/master/images/fitting.jpg\" height=300 width=500>\n",
    "\n",
    "The problem with just using training sets and test sets is that we might end up overfitting to to the test set as well.\n",
    "\n",
    "What we want to do is test on data we've never seen before.\n",
    "\n",
    "So we take a random 20% of the training set, and make that our validation set. That way we ensure we test against a random 20% each time. Also, we might not have the answers for the test set -- the whole point is that it's unseen data. But since the validation set comes from the training set, we know what it's meant to be.\n",
    "\n",
    "Reference:\n",
    "http://www.fast.ai/2017/11/13/validation-sets/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dropout\n",
    "When we are using a pretrained convolutional neural network (CNN), and we add a new layer to it, we are actually adding several new layers. After declaring your pretrained net as `learn = ...`, you can type `learn` to see which layers it added. By default tey will look like this:\n",
    "\n",
    "* BatchNorm1d: Covered later\n",
    "* Dropout\n",
    "* Linear: Does matrix multiplication -- takes the output from a convolution layer as input, and outputs to the number of classes\n",
    "* ReLU: Gets rid of -ves\n",
    "* BatchNorm1d\n",
    "* Dropout\n",
    "* Linear\n",
    "* LogSoftmax: The softmax layer to get a prediction (it uses log just for numerical accuracy sake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fastai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-02beb625e4fe>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfastai\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_learner\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fastai'"
     ]
    }
   ],
   "source": [
    "from fastai.conv_learner import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'planet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-0db86ef95fd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mPATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'data/planet/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mplanet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mf2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'planet'"
     ]
    }
   ],
   "source": [
    "PATH = 'data/planet/'\n",
    "\n",
    "from planet import f2\n",
    "\n",
    "metrics=[f2]\n",
    "f_model = resnet34\n",
    "\n",
    "# Set up our get_data function\n",
    "# This sets up our transforms and returns an image classifier which we can use to browse data, etc.\n",
    "# Notice this time we can set top-down transforms since we're using satellite data\n",
    "def get_data(image_size):\n",
    "    transforms = tfms_from_model(f_model, image_size, aug_tfms=transforms_top_down, max_zoom=1.05)\n",
    "    return ImageClassifierData.from_csv(PATH, \"train-jpg\", label_csv, tfms=transforms, \n",
    "                                        suffix=\".jpg\", val_idxs=val_idxs, test_name=\"test-jpg\")\n",
    "\n",
    "data = get_data(64)\n",
    "\n",
    "learn = ConvLearner.pretrained(f_model, data, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
